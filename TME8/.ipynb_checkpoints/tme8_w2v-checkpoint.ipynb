{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suite et fin du TME6: Classification de sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from nltk import stem\n",
    "import string\n",
    "import unicodedata\n",
    "import re\n",
    "import codecs\n",
    "import nltk.corpus.reader as pt\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path1='movies1000/pos'\n",
    "path2='movies1000/neg'\n",
    "rdr1 = pt.CategorizedPlaintextCorpusReader(path1, r'.*\\.txt', cat_pattern=r'(.*)\\.txt')\n",
    "rdr2 = pt.CategorizedPlaintextCorpusReader(path2, r'.*\\.txt', cat_pattern=r'(.*)\\.txt')\n",
    "\n",
    "def make_training_data(rdr):\n",
    "    for c in rdr.categories():\n",
    "        for f in rdr.fileids(c):\n",
    "            yield rdr.raw(fileids=[f])\n",
    "            \n",
    "            \n",
    "            \n",
    "#Création du corpus d'apprentissage à partir des fichiers dans movies1000            \n",
    "docs1=list(make_training_data(rdr1))\n",
    "y1=[1 for i in range(len(docs1))]\n",
    "docs2=list(make_training_data(rdr2))\n",
    "y2=[-1 for i in range(len(docs2))]\n",
    "X_raw=docs1+docs2\n",
    "y=y1+y2\n",
    "\n",
    "\n",
    "\n",
    "def readAFile(nf):\n",
    "    '''reads a file and extracts a list of strings \n",
    "    representing the ligns of the document.'''\n",
    "    f = open(nf, 'rb')\n",
    "    l = []\n",
    "    txt = f.readlines()\n",
    "    for i in txt:\n",
    "        l.append(i.decode(\"utf-8\"))\n",
    "    f.close()\n",
    "    return ' '.join(l)\n",
    "\n",
    "stopw=readAFile('stopwords.txt')\n",
    "stopw=stopw.split()\n",
    "\n",
    "\n",
    "def process(txt,stopw=None):\n",
    "    '''preprocessing of a string:\n",
    "            * decoding and ascii encoding\n",
    "            * punctuation elimination\n",
    "            * letters to lowercase\n",
    "            * stemming with snowball\n",
    "    '''\n",
    "    #txt = txt[txt.find(\"\\n\\n\"):] # elimination de l'entete (on ne conserve que les caractères après la première occurence du motif\n",
    "    txt = unicodedata.normalize(\"NFKD\",txt).encode(\"ascii\",\"ignore\") # elimination des caractères spéciaux, accents...\n",
    "    punc = string.punctuation    # recupération de la ponctuation\n",
    "    punc += u'\\n\\r\\t\\\\'          # ajouts de caractères à enlever\n",
    "    table =string.maketrans(punc, ' '*len(punc))  # table de conversion punc -> espace\n",
    "    txt = string.translate(txt,table).lower() # elimination des accents + minuscules\n",
    "    \n",
    "    #stemming\n",
    "    txt_list=txt.split()\n",
    "    snowball = stem.snowball.EnglishStemmer()\n",
    "    txt_list=[snowball.stem(w) for w in txt_list]\n",
    "    if(stopw):\n",
    "        txt_list=[w for w in txt_list if(w not in stopw)]\n",
    "    txt=' '.join(txt_list)\n",
    "    \n",
    "    return txt\n",
    "\n",
    "X_str=[process(x_str) for x_str in X_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* avant pre-processing:\n",
      "\n",
      "i've noticed something lately that i've never thought of before . \n",
      "pseudo- substance - hollywood faking deep meanings in their films . \n",
      "have you ever seen a movie that you really enjoyed , then when you look back , you realize there was something missing ? \n",
      "more and more , filmmakers seem to be putt\n",
      "\n",
      "\n",
      "* après pre-processing:\n",
      "\n",
      "i ve notic someth late that i ve never thought of befor pseudo substanc hollywood fake deep mean in their film have you ever seen a movi that you realli enjoy then when you look back you realiz there was someth miss more and more filmmak seem to be put out well rehears melodramat film that evok stro\n"
     ]
    }
   ],
   "source": [
    "print('* avant pre-processing:\\n')\n",
    "print(X_raw[11][:300]+'\\n\\n')\n",
    "\n",
    "print('* après pre-processing:\\n')\n",
    "print(X_str[11][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## du texte à la représentation vectorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "countVe = TfidfVectorizer(max_df=0.55, min_df=1, #max_features=1000,\n",
    "                    )\n",
    "count = countVe.fit_transform(X_str)\n",
    "X=count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## application de modèles d'apprentissage\n",
    "\n",
    "### naive bayes multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf=sklearn.naive_bayes.MultinomialNB()\n",
    "nb_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modèle maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.9, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxent_clf = sklearn.linear_model.LogisticRegression(max_iter=100,C=1.9)\n",
    "maxent_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm avec noyau linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = 2.6  # SVM regularization parameter\n",
    "svm_clf = svm.LinearSVC(C=C,max_iter=9000).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## résultats des expériences\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Note**: Nous utilisons içi des données de validation pour confronter nos différents modèles et représentations vectorielles, afin d'éviter le phénomène \"surapprentissage\" qui pourrait apparaître lors de la modification des hyperparamètres des modèles pour se \"coller\" au données de test. L'utilisation de données de validation nous permet donc de vérifier si un modèle et/ou une représentation est efficace, et les données de test nous permettent d'y attester en mesurant le pouvoir de généralisation de ce modèle avec ces hyperparamètres. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Note bis**: Au lieu d'utiliser le taux de bonne prédiction pour évaluer nos modèles, nous utilisons le f1-score qui est une moyenne pondérée de la précision et du rappel:\n",
    "\n",
    "\n",
    ">* **rappel**: $\\Large\\frac{\\textrm{vrais positifs}}{\\textrm{vrai positifs + faux négatifs}}$\n",
    "\n",
    "\n",
    ">* **précision**: $\\Large\\frac{\\textrm{vrais positifs}}{\\textrm{vrais positifs + faux positifs}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive bayes multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "nb_scores = cross_validation.cross_val_score(nb_clf, X, y, scoring='f1_weighted')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (nb_scores.mean(), nb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modèle maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "maxent_scores = cross_validation.cross_val_score(maxent_clf, X, y, scoring='f1_weighted')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (maxent_scores.mean(), maxent_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svm avec noyau linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "svm_scores = cross_validation.cross_val_score(svm_clf, X, y, scoring='f1_weighted')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (svm_scores.mean(), svm_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chargement des données test et pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_test='movies1000/test/'\n",
    "docs_test = readAFile(path_test+\"testSentiment.txt\")\n",
    "docs_test = docs_test.split('\\n')[0:-1]\n",
    "docs_test=[process(doc_test) for doc_test in docs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### représentation sous forme de sac de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_test = countVe.transform(docs_test)\n",
    "pred_labels=nb.predict(count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### écriture des résultats dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('sentim_exemple.txt', 'w')\n",
    "for i in pred_labels:\n",
    "    if i == -1:\n",
    "        f.write('C\\n')\n",
    "    else:\n",
    "        f.write('M\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation des coefficients des variables dans la base duale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Positive words:\n",
      "enjoy, fun, great, hilari, job, matrix, perfect, perform, surpris, well\n",
      "\n",
      "* Negative words: \n",
      "attempt, bad, bore, noth, plot, poor, suppos, unfortun, wast, worst\n"
     ]
    }
   ],
   "source": [
    "w=svm_clf.coef_[0].argsort()\n",
    "\n",
    "neg=np.array(w[:10])\n",
    "pos=np.array(w[-10:])\n",
    "test_pos=np.zeros((len(w)))\n",
    "test_pos[pos]=1\n",
    "test_neg=np.zeros((len(w)))\n",
    "test_neg[neg]=1\n",
    "\n",
    "ic_pos=countVe.inverse_transform(test_pos)\n",
    "ic_neg=countVe.inverse_transform(test_neg)\n",
    "\n",
    "print '* Positive words:'\n",
    "print ', '.join(ic_pos[0])\n",
    "print '\\n* Negative words: '\n",
    "print ', '.join(ic_neg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commentaires:\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nous avons confrontés nos résultats sur les données de validations aux données de test, pour attester du pouvoir de généralisation des modèles et des représentations en donnant le document <code>test_labels_exemple.txt</code> au serveur, accessible depuis le lien suivant:\n",
    "http://webia.lip6.fr/~guigue/wikihomepage/pmwiki.php?n=Course.CourseAFDSoumission\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Le modèle ayant le meilleur score sur les données de test est le svm (avec les paramètres définis plus haut). Nous avons utilisé une représentation sac de mots (sous forme TF-IDF cette fois-ci). Sur ces données un pre-processing des documents nous donne une meilleure classification. Nous obtenons un **score de 0.81549** sur les données de test. En observant les coefficients du svm, nous avon une idée des mots qui représentent des documents positifs ou négatifs. Ceux-ci correspondent intuivement à des mots positifs, et négatifs, respectivement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME8: word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.split()\n",
    "\n",
    "#Chargement de toutes les données de films\n",
    "path1='movies1000/all'\n",
    "sentences = MySentences(path1) # a memory-friendly iterator\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('husband', 0.8624480366706848)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['wife','woman'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plant', 0.7183860540390015),\n",
       " ('gun,', 0.710938572883606),\n",
       " ('fist', 0.709678053855896),\n",
       " ('car,', 0.7086430788040161),\n",
       " ('casino', 0.7047275900840759),\n",
       " ('lab', 0.6988829374313354),\n",
       " ('cattle', 0.6985705494880676),\n",
       " ('fires', 0.6964811086654663),\n",
       " ('uniform', 0.6962838172912598),\n",
       " ('tree', 0.6948219537734985)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['man','kitchen'], negative=['woman'], topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
